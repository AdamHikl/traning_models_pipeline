create a venv and install the following packages:

pip isntall torch
pip isntall transformers
pip isntall datasets
pip isntall peft
pip isntall bitsandbytes
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130


instructions:

after running the main.py, run the mergeTheModels.py

then git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
pip install -r requirements.txt

python convert_hf_to_gguf.py "C:\Users\adamh\Desktop\AI WORK\traning_models_pipeline\merged_model" --outfile hercule_poirot_f16.gguf --outtype f16

need to go use "x64 Native Tools Command Prompt for VS" instead of regular cmd

cmake --build build --config Release -j 16 (number of cpu cores)

.\build\bin\llama-quantize.exe hercule_poirot_f16_qwen3.gguf hercule_poirot_Q4_K_M_qwen3.gguf Q4_K_M

grab this model (hercule_poirot_Q4_K_M.gguf) and put it in "persona-chat\customModels" and create a corresponding modelFile

ollama create hercule-poirot -f ModelfileHerculePoirot


